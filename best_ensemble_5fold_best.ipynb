{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "best_ensemble_5fold_best.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNtfi/w++Kd5GEsNzNnPFeD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/shopee/blob/main/best_ensemble_5fold_best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH4BUYQATECs"
      },
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import tensorflow as tf\n",
        "!pip install ../input/keras-efficientnet-whl/Keras_Applications-1.0.8-py3-none-any.whl\n",
        "!pip install ../input/keras-efficientnet-whl/efficientnet-1.1.1-py3-none-any.whl\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "116CD1DUTMxu"
      },
      "source": [
        "LIMIT = 1\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],\n",
        "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "print('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\n",
        "print('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHOCSCkrTMvx"
      },
      "source": [
        "import efficientnet.tfkeras as efn\n",
        "from tqdm.notebook import tqdm\n",
        "import math\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# Configuration\n",
        "BATCH_SIZE = 8\n",
        "IMAGE_SIZE = [512, 512]\n",
        "# Seed\n",
        "SEED = 42\n",
        "# Verbosity\n",
        "VERBOSE = 1\n",
        "# Number of classes of each fold\n",
        "N_CLASSES = [8811, 8811, 8811, 8812, 8811]\n",
        "GET_CV = True\n",
        "# Flag to check ram allocations (debug)\n",
        "CHECK_SUB = False\n",
        "\n",
        "df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
        "# If we are comitting, replace train set for test set and dont get cv\n",
        "if len(df) > 3:\n",
        "    GET_CV = False\n",
        "del df\n",
        "\n",
        "# Function to get our f1 score\n",
        "def f1_score(y_true, y_pred):\n",
        "    y_true = y_true.apply(lambda x: set(x.split()))\n",
        "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
        "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
        "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
        "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
        "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
        "    return f1\n",
        "\n",
        "# Function to read out dataset\n",
        "def read_dataset():\n",
        "    \n",
        "    df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
        "    image_paths = '../input/shopee-product-matching/test_images/' + df['image']\n",
        "        \n",
        "    return df, image_paths\n",
        "\n",
        "# Function to decode our images\n",
        "def decode_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
        "    image = tf.image.resize(image, IMAGE_SIZE)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "# Function to read our test image and return image\n",
        "def read_image(image):\n",
        "    image = tf.io.read_file(image)\n",
        "    image = decode_image(image)\n",
        "    return image\n",
        "\n",
        "# Function to get our dataset that read images\n",
        "def get_dataset(image):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(image)\n",
        "    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "# Arcmarginproduct class keras layer\n",
        "class ArcMarginProduct(tf.keras.layers.Layer):\n",
        "    '''\n",
        "    Implements large margin arc distance.\n",
        "\n",
        "    Reference:\n",
        "        https://arxiv.org/pdf/1801.07698.pdf\n",
        "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
        "            blob/master/src/modeling/metric_learning.py\n",
        "    '''\n",
        "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
        "                 ls_eps=0.0, **kwargs):\n",
        "\n",
        "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.ls_eps = ls_eps\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = tf.math.cos(m)\n",
        "        self.sin_m = tf.math.sin(m)\n",
        "        self.th = tf.math.cos(math.pi - m)\n",
        "        self.mm = tf.math.sin(math.pi - m) * m\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'n_classes': self.n_classes,\n",
        "            's': self.s,\n",
        "            'm': self.m,\n",
        "            'ls_eps': self.ls_eps,\n",
        "            'easy_margin': self.easy_margin,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(ArcMarginProduct, self).build(input_shape[0])\n",
        "\n",
        "        self.W = self.add_weight(\n",
        "            name='W',\n",
        "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
        "            initializer='glorot_uniform',\n",
        "            dtype='float32',\n",
        "            trainable=True,\n",
        "            regularizer=None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        X, y = inputs\n",
        "        y = tf.cast(y, dtype=tf.int32)\n",
        "        cosine = tf.matmul(\n",
        "            tf.math.l2_normalize(X, axis=1),\n",
        "            tf.math.l2_normalize(self.W, axis=0)\n",
        "        )\n",
        "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = tf.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        one_hot = tf.cast(\n",
        "            tf.one_hot(y, depth=self.n_classes),\n",
        "            dtype=cosine.dtype\n",
        "        )\n",
        "        if self.ls_eps > 0:\n",
        "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
        "\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output *= self.s\n",
        "        return output\n",
        "\n",
        "# Function to get the embeddings of our images with the fine-tuned model\n",
        "\n",
        "\n",
        "# Function to get our text title embeddings\n",
        "def get_text_embeddings(df, max_features = 15500):\n",
        "    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n",
        "    text_embeddings = model.fit_transform(df['title'])\n",
        "    print(f'Our title text embedding shape is {text_embeddings.shape}')\n",
        "    del model\n",
        "    return text_embeddings\n",
        "\n",
        "# Function to get 50 nearest neighbors of each image and text and apply thresholds find in the training phase that optimize f1 cv score\n",
        "def get_neighbors(df, image_embeddings, text_embeddings, KNN = 50):\n",
        "    # Get distances and indices from image and text embeddings\n",
        "    neighbors_model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine').fit(image_embeddings)\n",
        "    image_distances, image_indices = neighbors_model.kneighbors(image_embeddings)\n",
        "    neighbors_model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine').fit(text_embeddings)\n",
        "    text_distances, text_indices = neighbors_model.kneighbors(text_embeddings)\n",
        "  \n",
        "    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n",
        "    if GET_CV:\n",
        "        predictions = []\n",
        "        for k in range(df.shape[0]):\n",
        "            # This are the original thresholds that gives 0.8035 cv (optimize with a for loop)\n",
        "            idx_image = np.where(image_distances[k,] < 0.35)[0]\n",
        "            ids_image = image_indices[k,idx_image]\n",
        "            idx_text = np.where(text_distances[k,] < 0.30)[0]\n",
        "            ids_text = text_indices[k,idx_text]\n",
        "            # Get the union of boths ids\n",
        "            ids = list(set(list(ids_image) + list(ids_text)))\n",
        "            posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
        "            predictions.append(posting_ids)\n",
        "    \n",
        "    else:\n",
        "        predictions = []\n",
        "        for k in range(df.shape[0]):\n",
        "            # Reduce the thresholds because we are predicting more observations\n",
        "            idx_image = np.where(image_distances[k,] < 0.35)[0]\n",
        "            ids_image = image_indices[k,idx_image]\n",
        "            idx_text = np.where(text_distances[k,] < 0.21)[0]\n",
        "            ids_text = text_indices[k,idx_text]\n",
        "            # Get the union of boths ids\n",
        "            ids = list(set(list(ids_image) + list(ids_text)))\n",
        "            posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
        "            predictions.append(posting_ids)\n",
        "        \n",
        "    del neighbors_model, image_distances, image_indices, text_distances, text_indices\n",
        "    gc.collect()\n",
        "    return df, predictions\n",
        "\n",
        "# Read data and image paths\n",
        "df, image_paths = read_dataset()\n",
        "def get_image_embeddings(image_paths, fold = 4):\n",
        "    embeds = []\n",
        "    \n",
        "    if fold == 3:\n",
        "        mod = efn.EfficientNetB3(weights = None, include_top = False)\n",
        "    elif fold == 2:\n",
        "        mod = efn.EfficientNetB2(weights = None, include_top = False)\n",
        "    elif fold == 1:\n",
        "        mod = efn.EfficientNetB1(weights = None, include_top = False)\n",
        "    elif fold == 0:\n",
        "        mod = efn.EfficientNetB0(weights = None, include_top = False)\n",
        "\n",
        "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
        "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
        "    x = mod(inp)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    margin = ArcMarginProduct(\n",
        "                n_classes = 11014, \n",
        "                s = 30, \n",
        "                m = 0.7, \n",
        "                name='head/arc_margin', \n",
        "                dtype='float32'\n",
        "                )\n",
        "    x = margin([x, label])\n",
        "        \n",
        "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
        "    if fold == 3:\n",
        "        model.load_weights('../input/se-weights/b3.hdf5')\n",
        "    elif fold == 2:\n",
        "        model.load_weights('../input/se-weights/b2.hdf5')\n",
        "    elif fold == 1:\n",
        "        model.load_weights('../input/se-weights/b1.hdf5')\n",
        "    elif fold == 0:\n",
        "        model.load_weights('../input/se-weights/b0.hdf5')\n",
        "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n",
        "    chunk = 5000\n",
        "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
        "    for j in tqdm(iterator):\n",
        "        a = int(j * chunk)\n",
        "        b = int((j + 1) * chunk)\n",
        "        image_dataset = get_dataset(image_paths[a:b])\n",
        "        image_embeddings = model.predict(image_dataset)\n",
        "        embeds.append(image_embeddings)\n",
        "    del model\n",
        "    image_embeddings = np.concatenate(embeds)\n",
        "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
        "    del embeds\n",
        "    gc.collect()\n",
        "    return image_embeddings\n",
        "\n",
        "image_embeddings_4 = get_image_embeddings(image_paths, fold = 0)\n",
        "image_embeddings_3 = get_image_embeddings(image_paths, fold = 3)\n",
        "image_embeddings_2 = get_image_embeddings(image_paths, fold = 2)\n",
        "image_embeddings_1 = get_image_embeddings(image_paths, fold = 1)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q4w1stOTMtj"
      },
      "source": [
        "    text_embeddings = get_text_embeddings(df, max_features = 25000)\n",
        "    image_embeddings = np.average([image_embeddings_4, image_embeddings_3[:,:1280], image_embeddings_2[:,:1280], image_embeddings_1[:,:1280]], axis = 0)\n",
        "    if GET_CV:\n",
        "        KNN=3\n",
        "    else:\n",
        "        KNN=50\n",
        "    neighbors_model = NearestNeighbors(n_neighbors = KNN,metric='cosine').fit(image_embeddings)\n",
        "    image_distances, image_indices = neighbors_model.kneighbors(image_embeddings)\n",
        "    neighbors_model = NearestNeighbors(n_neighbors = KNN).fit(text_embeddings)\n",
        "    text_distances, text_indices = neighbors_model.kneighbors(text_embeddings)\n",
        "    print('got it')\n",
        "    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n",
        "    if GET_CV:\n",
        "        predictions = []\n",
        "        for k in range(df.shape[0]):\n",
        "            # This are the original thresholds that gives 0.8035 cv (optimize with a for loop)\n",
        "            idx_image = np.where(image_distances[k,] < 0.25)[0]\n",
        "            ids_image = image_indices[k,idx_image]\n",
        "            idx_text = np.where(text_distances[k,] < 0.6)[0]\n",
        "            ids_text = text_indices[k,idx_text]\n",
        "            # Get the union of boths ids\n",
        "            ids = list(set(list(ids_image) + list(ids_text)))\n",
        "            posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
        "            predictions.append(posting_ids)\n",
        "    \n",
        "    else:\n",
        "        predictions = []\n",
        "        for k in range(df.shape[0]):\n",
        "            # Reduce the thresholds because we are predicting more observations\n",
        "            idx_image = np.where(image_distances[k,] <0.35)[0]\n",
        "            ids_image = image_indices[k,idx_image]\n",
        "            idx_text = np.where(text_distances[k,] < 0.7)[0]\n",
        "            ids_text = text_indices[k,idx_text]\n",
        "            # Get the union of boths ids\n",
        "            ids = list(set(list(ids_image) + list(ids_text)))\n",
        "            posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
        "            predictions.append(posting_ids)\n",
        "        \n",
        "    del neighbors_model, image_distances, image_indices, text_distances, text_indices\n",
        "    gc.collect()\n",
        "    neighbors_model = NearestNeighbors(n_neighbors = KNN).fit(image_embeddings_2)\n",
        "    image_distances, image_indices = neighbors_model.kneighbors(image_embeddings_2)\n",
        "    neighbors_model = NearestNeighbors(n_neighbors = KNN).fit(image_embeddings_1)\n",
        "    text_distances, text_indices = neighbors_model.kneighbors(image_embeddings_1)\n",
        "    predictions1 = []\n",
        "    for k in range(df.shape[0]):\n",
        "            # This are the original thresholds that gives 0.8035 cv (optimize with a for loop)\n",
        "            idx_image = np.where(image_distances[k,] < 0.5)[0]\n",
        "            ids_image = image_indices[k,idx_image]\n",
        "            idx_text = np.where(text_distances[k,] < 0.5)[0]\n",
        "            ids_text = text_indices[k,idx_text]\n",
        "            ids = list(set(list(ids_image) + list(ids_text)))\n",
        "            posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
        "            predictions1.append(posting_ids)\n",
        "    \n",
        "    del neighbors_model, image_distances, image_indices, text_distances, text_indices\n",
        "    gc.collect()\n",
        "    neighbors_model = NearestNeighbors(n_neighbors = KNN).fit(image_embeddings_3)\n",
        "    text_distances, text_indices = neighbors_model.kneighbors(image_embeddings_3)\n",
        "    neighbors_model_1 = NearestNeighbors(n_neighbors = KNN).fit(image_embeddings_4)\n",
        "    text_distances_1, text_indices_1 = neighbors_model_1.kneighbors(image_embeddings_4)\n",
        "    predictions2 = []\n",
        "    for k in range(df.shape[0]):\n",
        "            # This are the original thresholds that gives 0.8035 cv (optimize with a for loop)\n",
        "            idx_text = np.where(text_distances[k,] < 0.5)[0]\n",
        "            ids_text = text_indices[k,idx_text]\n",
        "            idx_text1 = np.where(text_distances_1[k,] < 0.5)[0]\n",
        "            ids_text1 = text_indices[k,idx_text]\n",
        "            # Get the union of boths idsi\n",
        "            ids = list(set(list(ids_text)+ list(ids_text1)))\n",
        "            posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
        "            predictions2.append(posting_ids)\n",
        "    del neighbors_model, text_distances, text_indices,neighbors_model_1,text_distances_1, text_indices_1\n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYAXv-VFTMq8"
      },
      "source": [
        "del([image_embeddings_4, image_embeddings_3, image_embeddings_2, image_embeddings_1])\n",
        "gc.collect()\n",
        "def get_image_embeddings(image_paths, fold = 4):\n",
        "    embeds = []\n",
        "    \n",
        "    if fold == 4:\n",
        "        margin = ArcMarginProduct(\n",
        "                n_classes =8793, \n",
        "                s = 30, \n",
        "                m = 0.7, \n",
        "                name='head/arc_margin', \n",
        "                dtype='float32'\n",
        "                )\n",
        "    elif fold == 3:\n",
        "        margin = ArcMarginProduct(\n",
        "                n_classes = 8804, \n",
        "                s = 30, \n",
        "                m = 0.7, \n",
        "                name='head/arc_margin', \n",
        "                dtype='float32'\n",
        "                )\n",
        "    elif fold == 2:\n",
        "        margin = ArcMarginProduct(\n",
        "                n_classes = 8811, \n",
        "                s = 30, \n",
        "                m = 0.7, \n",
        "                name='head/arc_margin', \n",
        "                dtype='float32'\n",
        "                )\n",
        "    elif fold == 1:\n",
        "        margin = ArcMarginProduct(\n",
        "                n_classes = 8819, \n",
        "                s = 30, \n",
        "                m = 0.7, \n",
        "                name='head/arc_margin', \n",
        "                dtype='float32'\n",
        "                )\n",
        "    elif fold == 0:\n",
        "        margin = ArcMarginProduct(\n",
        "                n_classes = 8829, \n",
        "                s = 30, \n",
        "                m = 0.7, \n",
        "                name='head/arc_margin', \n",
        "                dtype='float32'\n",
        "                )\n",
        "\n",
        "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
        "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
        "    x = efn.EfficientNetB0(weights = None, include_top = False)(inp)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = margin([x, label])\n",
        "        \n",
        "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
        "    if fold == 4:\n",
        "        model.load_weights('../input/b0-5fold/results(5)/weights.hdf5')\n",
        "    elif fold == 3:\n",
        "        model.load_weights('../input/b0-5fold/results(4)/weights.hdf5')\n",
        "    elif fold == 2:\n",
        "        model.load_weights('../input/b0-5fold/results(3)/weights.hdf5')\n",
        "    elif fold == 1:\n",
        "        model.load_weights('../input/b0-5fold/results(2)/weights.hdf5')\n",
        "    elif fold == 0:\n",
        "        model.load_weights('../input/b0-5fold/weights(1).hdf5')\n",
        "    print('done')\n",
        "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n",
        "    chunk = 5000\n",
        "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
        "    for j in iterator:\n",
        "        a = int(j * chunk)\n",
        "        b = int((j + 1) * chunk)\n",
        "        image_dataset = get_dataset(image_paths[a:b])\n",
        "        image_embeddings = model.predict(image_dataset)\n",
        "        embeds.append(image_embeddings)\n",
        "    del model\n",
        "    image_embeddings = np.concatenate(embeds)\n",
        "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
        "    del embeds\n",
        "    gc.collect()\n",
        "    return image_embeddings\n",
        "\n",
        "image_embeddings_4 = get_image_embeddings(image_paths.values, fold = 4)\n",
        "image_embeddings_3 = get_image_embeddings(image_paths.values, fold = 3)\n",
        "image_embeddings_2 = get_image_embeddings(image_paths.values, fold = 2)\n",
        "image_embeddings_1 = get_image_embeddings(image_paths.values, fold = 1)\n",
        "image_embeddings_0 = get_image_embeddings(image_paths.values, fold = 0)\n",
        "image_embeddings = np.average([image_embeddings_4, image_embeddings_3, image_embeddings_1, image_embeddings_0], axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tq9wNjbTMoM"
      },
      "source": [
        "del ([image_embeddings_4, image_embeddings_3, image_embeddings_1, image_embeddings_0])\n",
        "gc.collect()\n",
        "def get_neighbors(df, embeddings,threshold = 0.0):\n",
        "    \n",
        "    if len(df) > 3:\n",
        "        KNN = 50\n",
        "    else : \n",
        "        KNN = 3\n",
        "    \n",
        "    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')\n",
        "    model.fit(embeddings)\n",
        "    distances, indices = model.kneighbors(embeddings)\n",
        "    \n",
        "    predictions = []\n",
        "    for k in tqdm(range(embeddings.shape[0])):\n",
        "        idx = np.where(distances[k,] < threshold)[0]\n",
        "        ids = indices[k,idx]\n",
        "        posting_ids =' '.join(df['posting_id'].iloc[ids].values)\n",
        "        predictions.append(posting_ids)\n",
        "        \n",
        "    del model, distances, indices\n",
        "    gc.collect()\n",
        "    return predictions\n",
        "\n",
        "\n",
        "predictions4 = get_neighbors(df, image_embeddings, threshold=0.35)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxRicAgaTWM_"
      },
      "source": [
        "df['pre1']=predictions\n",
        "df['pre2']=predictions1\n",
        "df['pre3']=predictions2\n",
        "df['pre4']=predictions4\n",
        "def combine_predictions(row):\n",
        "    x = list(set(row['pre1'].split(' ')).union(set(row['pre4'].split(' ')).intersection(row['pre3'].split(' ')).intersection(set(row['pre2'].split(' ')))))\n",
        "    return ' '.join( np.unique(x))\n",
        "# Get neighbors\n",
        "df['matches'] = df.apply(combine_predictions, axis = 1)\n",
        "df[['posting_id', 'matches']].to_csv('submission.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}