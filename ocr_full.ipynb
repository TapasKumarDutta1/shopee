{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ocr_full",
      "provenance": [],
      "authorship_tag": "ABX9TyONlO7f5Z5gWu6fF510sgzo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/shopee/blob/main/ocr_full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxU7chZVTbLj"
      },
      "source": [
        "import numpy as np, pandas as pd, gc\n",
        "import cv2, matplotlib.pyplot as plt\n",
        "import cudf, cuml, cupy\n",
        "from cuml.feature_extraction.text import TfidfVectorizer\n",
        "from cuml.neighbors import NearestNeighbors\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "print('RAPIDS',cuml.__version__)\n",
        "print('TF',tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sLS0CSdY33i"
      },
      "source": [
        "\n",
        "!pip install ../input/keras-efficientnet-whl/Keras_Applications-1.0.8-py3-none-any.whl\n",
        "!pip install ../input/keras-efficientnet-whl/efficientnet-1.1.1-py3-none-any.whl\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahwfdhdhY30o"
      },
      "source": [
        "LIMIT = 1\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],\n",
        "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "print('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\n",
        "print('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih_ev6ToY3xn"
      },
      "source": [
        "COMPUTE_CV = True\n",
        "\n",
        "test = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
        "if len(test)>3: COMPUTE_CV = False\n",
        "else: print('this submission notebook will compute CV score, but commit notebook will not')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oee4oCeBY3u_"
      },
      "source": [
        "\n",
        "\n",
        "train = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
        "tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n",
        "train['target'] = train.label_group.map(tmp)\n",
        "print('train shape is', train.shape )\n",
        "train.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VQ1AIcoY3sX"
      },
      "source": [
        "tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\n",
        "train['oof'] = train.image_phash.map(tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiDHkSJ8Y3ps"
      },
      "source": [
        "\n",
        "\n",
        "def getMetric(col):\n",
        "    def f1score(row):\n",
        "        n = len( np.intersect1d(row.target,row[col]) )\n",
        "        return 2*n / (len(row.target)+len(row[col]))\n",
        "    return f1score\n",
        "\n",
        "train['f1'] = train.apply(getMetric('oof'),axis=1)\n",
        "print('CV score for baseline =',train.f1.mean())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDd3h_E9Y3nC"
      },
      "source": [
        "if COMPUTE_CV:\n",
        "    test = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
        "    test_gf = cudf.DataFrame(test)\n",
        "    print('Using train as test to compute CV (since commit notebook). Shape is', test_gf.shape )\n",
        "else:\n",
        "    test = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
        "    test_gf = cudf.read_csv('../input/shopee-product-matching/test.csv')\n",
        "    print('Test shape is', test_gf.shape )\n",
        "test_gf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOecOpPrZFFn"
      },
      "source": [
        "\n",
        "\n",
        "print('Computing text embeddings...')\n",
        "model = TfidfVectorizer(stop_words='english', binary=True, max_features=25_000)\n",
        "text_embeddings = model.fit_transform(test_gf.title).toarray()\n",
        "print('text embeddings shape',text_embeddings.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClpHiffnZFCf"
      },
      "source": [
        "preds = []\n",
        "CHUNK = 1024*4\n",
        "\n",
        "print('Finding similar titles...')\n",
        "CTS = len(test)//CHUNK\n",
        "if len(test)%CHUNK!=0: CTS += 1\n",
        "for j in range( CTS ):\n",
        "    \n",
        "    a = j*CHUNK\n",
        "    b = (j+1)*CHUNK\n",
        "    b = min(b,len(test))\n",
        "    print('chunk',a,'to',b)\n",
        "    \n",
        "    # COSINE SIMILARITY DISTANCE\n",
        "    cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n",
        "    \n",
        "    for k in range(b-a):\n",
        "        IDX = cupy.where(cts[k,]>0.7)[0]\n",
        "        o = test.iloc[cupy.asnumpy(IDX)].posting_id.values\n",
        "        preds.append(o)\n",
        "        \n",
        "del model, text_embeddings\n",
        "_ = gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiMgtER0ZE_x"
      },
      "source": [
        "test['preds'] = preds\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSx_yv17ZIe3"
      },
      "source": [
        "\n",
        "\n",
        "tmp = test.groupby('image_phash').posting_id.agg('unique').to_dict()\n",
        "test['preds3'] = test.image_phash.map(tmp)\n",
        "test.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CqE7HMYZIcK"
      },
      "source": [
        "def combine_for_sub(row):\n",
        "    x = np.concatenate([row.preds, row.preds3])\n",
        "    return ' '.join( np.unique(x) )\n",
        "\n",
        "def combine_for_cv(row):\n",
        "    x = np.concatenate([row.preds, row.preds3])\n",
        "    return np.unique(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6eCy5xNZIZk"
      },
      "source": [
        "if COMPUTE_CV:\n",
        "    tmp = test.groupby('label_group').posting_id.agg('unique').to_dict()\n",
        "    test['target'] = test.label_group.map(tmp)\n",
        "    test['oof'] = test.apply(combine_for_cv,axis=1)\n",
        "    test['f1'] = test.apply(getMetric('oof'),axis=1)\n",
        "    print('CV Score =', test.f1.mean() )\n",
        "\n",
        "test['matches'] = test.apply(combine_for_sub,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_kuKnimZLEf"
      },
      "source": [
        "test[['posting_id','matches']].to_csv('submission.csv',index=False)\n",
        "sub = pd.read_csv('submission.csv')\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}